import { useEffect, useRef, useCallback, useState } from 'react'
import useStateWithCallback from './useStateWithCallback'
import ACTIONS from '../backend/actions'
import { useSocket } from '../SocketContext'

export const LOCAL_VIDEO = 'LOCAL_VIDEO'

export default function useWebRTC(roomID) {
  const { socket } = useSocket()
  const [clients, updateClients] = useStateWithCallback([])
  const [isSpeaking, setIsSpeaking] = useState(false)
  const [thresholdDb, setThresholdDb] = useState(-42) // Ñ€Ð°Ð·ÑƒÐ¼Ð½Ñ‹Ð¹ Ð´ÐµÑ„Ð¾Ð»Ñ‚, Ð¼Ð¾Ð¶Ð½Ð¾ Ñ€ÐµÐ³ÑƒÐ»Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ

  const addNewClient = useCallback(
    (newClient, cb) => {
      updateClients((list) => {
        if (!list.includes(newClient)) return [...list, newClient]
        return list
      }, cb)
    },
    [updateClients]
  )

  const peerConnections = useRef({})
  const localMediaStream = useRef(null)
  const peerMediaElements = useRef({ [LOCAL_VIDEO]: null })

  const audioContext = useRef(null)
  const gainNode = useRef(null)
  const audioSource = useRef(null)
  const analyserRef = useRef(null)

  const speakingCheckInterval = useRef(null)
  const silenceTimeout = useRef(null)
  const isSpeakingRef = useRef(false)
  const thresholdRef = useRef(thresholdDb)

  // keep thresholdRef in sync so interval handler uses latest value
  useEffect(() => {
    thresholdRef.current = thresholdDb
  }, [thresholdDb])

  // === ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° ÑƒÑ€Ð¾Ð²Ð½Ñ Ð·Ð²ÑƒÐºÐ° (RMS -> dB) Ñ Ð³Ð¸ÑÑ‚ÐµÑ€ÐµÐ·Ð¸ÑÐ¾Ð¼ ===
  const checkAudioLevel = useCallback(() => {
    try {
      if (!analyserRef.current || !gainNode.current || !audioContext.current)
        return

      const analyser = analyserRef.current
      const bufferLen = analyser.fftSize
      const data = new Uint8Array(bufferLen)
      analyser.getByteTimeDomainData(data) // time-domain 0..255

      // compute RMS
      let sum = 0
      for (let i = 0; i < bufferLen; i++) {
        const v = (data[i] - 128) / 128 // -1..1
        sum += v * v
      }
      const rms = Math.sqrt(sum / bufferLen)

      // avoid -Infinity; set floor
      const db = rms > 1e-8 ? 20 * Math.log10(rms) : -100

      const currentThreshold = thresholdRef.current
      const isCurrentlySpeaking = db > currentThreshold

      // immediate ON, delayed OFF (hysteresis)
      if (isCurrentlySpeaking && !isSpeakingRef.current) {
        if (silenceTimeout.current) {
          clearTimeout(silenceTimeout.current)
          silenceTimeout.current = null
        }
        isSpeakingRef.current = true
        setIsSpeaking(true)
        // fade in quickly
        gainNode.current.gain.cancelScheduledValues(
          audioContext.current.currentTime
        )
        gainNode.current.gain.setTargetAtTime(
          1.0,
          audioContext.current.currentTime,
          0.01
        )
        // debug
        // console.log('ðŸ”Š Ð“Ð¾Ð²Ð¾Ñ€Ð¸Ñ‚', `RMS:${rms.toFixed(5)} dB:${db.toFixed(1)} thr:${currentThreshold}`)
      }

      if (!isCurrentlySpeaking && isSpeakingRef.current) {
        // wait 150ms of silence before turning off
        if (!silenceTimeout.current) {
          silenceTimeout.current = setTimeout(() => {
            isSpeakingRef.current = false
            setIsSpeaking(false)
            gainNode.current.gain.cancelScheduledValues(
              audioContext.current.currentTime
            )
            gainNode.current.gain.setTargetAtTime(
              0.0,
              audioContext.current.currentTime,
              0.05
            )
            silenceTimeout.current = null
            // console.log('ðŸ”‡ Ð¢Ð¸ÑˆÐ¸Ð½Ð°', `dB:${db.toFixed(1)} thr:${currentThreshold}`)
          }, 150)
        }
      }
    } catch (err) {
      // Ð½Ðµ Ð»Ð¾Ð¼Ð°ÐµÐ¼ Ð²ÑÑ‘ Ð¸Ð·-Ð·Ð° Ð¾ÑˆÐ¸Ð±Ð¾Ðº Ð°Ð½Ð°Ð»Ð¸Ð·Ð°
      // console.warn('checkAudioLevel error', err)
    }
  }, [])

  // === Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð°ÑƒÐ´Ð¸Ð¾ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð° Ð¸ GainNode ===
  useEffect(() => {
    try {
      audioContext.current = new (window.AudioContext ||
        window.webkitAudioContext)({
        sampleRate: 48000,
        latencyHint: 'interactive',
      })
      gainNode.current = audioContext.current.createGain()
      gainNode.current.gain.value = 0 // Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ Ð·Ð°Ð³Ð»ÑƒÑˆÐµÐ½Ð¾, VAD Ð¾Ñ‚ÐºÑ€Ð¾ÐµÑ‚ Ð¿Ñ€Ð¸ Ð³Ð¾Ð»Ð¾ÑÐµ
    } catch (error) {
      console.warn('Failed to initialize audio processing:', error)
    }

    return () => {
      try {
        if (speakingCheckInterval.current) {
          clearInterval(speakingCheckInterval.current)
          speakingCheckInterval.current = null
        }
        if (silenceTimeout.current) {
          clearTimeout(silenceTimeout.current)
          silenceTimeout.current = null
        }
        if (audioSource.current) {
          try {
            audioSource.current.disconnect()
          } catch (e) {}
          audioSource.current = null
        }
        if (analyserRef.current) {
          try {
            analyserRef.current.disconnect()
          } catch (e) {}
          analyserRef.current = null
        }
        if (gainNode.current) {
          try {
            gainNode.current.disconnect()
          } catch (e) {}
          gainNode.current = null
        }
        if (audioContext.current) {
          audioContext.current.close()
          audioContext.current = null
        }
      } catch (e) {
        // ignore
      }
    }
  }, [])

  // === ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð°ÑƒÐ´Ð¸Ð¾ Ð¿Ð¾Ñ‚Ð¾ÐºÐ°: Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡Ð°ÐµÐ¼ analyser -> gain -> destination ===
  const processAudioStream = useCallback(
    async (originalStream) => {
      if (!audioContext.current || !gainNode.current) return originalStream

      try {
        // ÐµÑÐ»Ð¸ Ð±Ñ‹Ð» Ð¿Ñ€ÐµÐ´Ñ‹Ð´ÑƒÑ‰Ð¸Ð¹ Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸Ðº â€” Ð¾Ñ‚ÑÐ¾ÐµÐ´Ð¸Ð½ÑÐµÐ¼
        if (audioSource.current) {
          try {
            audioSource.current.disconnect()
          } catch (e) {}
          audioSource.current = null
        }
        if (analyserRef.current) {
          try {
            analyserRef.current.disconnect()
          } catch (e) {}
          analyserRef.current = null
        }

        // ÑÐ¾Ð·Ð´Ð°Ñ‘Ð¼ Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸Ðº, Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€ Ð¸ destination
        audioSource.current =
          audioContext.current.createMediaStreamSource(originalStream)

        analyserRef.current = audioContext.current.createAnalyser()
        analyserRef.current.fftSize = 512
        analyserRef.current.smoothingTimeConstant = 0.3

        const audioDestination =
          audioContext.current.createMediaStreamDestination()

        // Ñ†ÐµÐ¿Ð¾Ñ‡ÐºÐ°: source -> analyser -> gain -> destination
        audioSource.current.connect(analyserRef.current)
        analyserRef.current.connect(gainNode.current)
        gainNode.current.connect(audioDestination)

        // Ð¾Ñ‡Ð¸ÑÑ‚Ð¸Ð¼ ÑÑ‚Ð°Ñ€Ñ‹Ð¹ Ð¸Ð½Ñ‚ÐµÑ€Ð²Ð°Ð», ÐµÑÐ»Ð¸ Ð±Ñ‹Ð»
        if (speakingCheckInterval.current) {
          clearInterval(speakingCheckInterval.current)
        }
        // Ð·Ð°Ð¿ÑƒÑÐº Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ¸ ÑƒÑ€Ð¾Ð²Ð½Ñ
        speakingCheckInterval.current = setInterval(checkAudioLevel, 100)

        // ÑÐ¾Ð±Ð¸Ñ€Ð°ÐµÐ¼ Ñ„Ð¸Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð¿Ð¾Ñ‚Ð¾Ðº (Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½Ð½Ñ‹Ð¹ Ð°ÑƒÐ´Ð¸Ð¾ + Ð¾Ñ€Ð¸Ð³Ð¸Ð½Ð°Ð»ÑŒÐ½Ð¾Ðµ Ð²Ð¸Ð´ÐµÐ¾)
        const processedStream = new MediaStream()
        audioDestination.stream
          .getAudioTracks()
          .forEach((t) => processedStream.addTrack(t))
        originalStream
          .getVideoTracks()
          .forEach((t) => processedStream.addTrack(t))

        return processedStream
      } catch (error) {
        console.error('Audio processing failed:', error)
        return originalStream
      }
    },
    [checkAudioLevel]
  )

  // --- Peer connection handlers (ÐºÐ°Ðº Ð² ÑÑ‚Ð°Ñ€Ð¾Ð¹ Ð²ÐµÑ€ÑÐ¸Ð¸) ---
  useEffect(() => {
    async function handleNewPeer({ peerID, createOffer }) {
      if (peerID in peerConnections.current) {
        return console.warn(`Already connected to peer ${peerID}`)
      }

      peerConnections.current[peerID] = new RTCPeerConnection({
        iceServers: [{ urls: 'stun:stun.l.google.com:19302' }],
      })

      peerConnections.current[peerID].onicecandidate = (event) => {
        if (event.candidate) {
          socket.emit(ACTIONS.RELAY_ICE, {
            peerID,
            iceCandidate: event.candidate,
          })
        }
      }

      let tracksNumber = 0
      peerConnections.current[peerID].ontrack = ({
        streams: [remoteStream],
      }) => {
        tracksNumber++
        if (tracksNumber === 2) {
          tracksNumber = 0
          addNewClient(peerID, () => {
            if (peerMediaElements.current[peerID]) {
              peerMediaElements.current[peerID].srcObject = remoteStream
            } else {
              let settled = false
              const interval = setInterval(() => {
                if (peerMediaElements.current[peerID]) {
                  peerMediaElements.current[peerID].srcObject = remoteStream
                  settled = true
                }
                if (settled) clearInterval(interval)
              }, 1000)
            }
          })
        }
      }

      if (localMediaStream.current) {
        localMediaStream.current.getTracks().forEach((track) => {
          peerConnections.current[peerID].addTrack(
            track,
            localMediaStream.current
          )
        })
      }

      if (createOffer) {
        const offer = await peerConnections.current[peerID].createOffer()
        await peerConnections.current[peerID].setLocalDescription(offer)
        socket.emit(ACTIONS.RELAY_SDP, { peerID, sessionDescription: offer })
      }
    }

    socket.on(ACTIONS.ADD_PEER, handleNewPeer)
    return () => socket.off(ACTIONS.ADD_PEER)
  }, [socket, addNewClient])

  useEffect(() => {
    async function setRemoteMedia({
      peerID,
      sessionDescription: remoteDescription,
    }) {
      await peerConnections.current[peerID]?.setRemoteDescription(
        new RTCSessionDescription(remoteDescription)
      )
      if (remoteDescription.type === 'offer') {
        const answer = await peerConnections.current[peerID].createAnswer()
        await peerConnections.current[peerID].setLocalDescription(answer)
        socket.emit(ACTIONS.RELAY_SDP, { peerID, sessionDescription: answer })
      }
    }

    socket.on(ACTIONS.SESSION_DESCRIPTION, setRemoteMedia)
    return () => socket.off(ACTIONS.SESSION_DESCRIPTION)
  }, [socket])

  useEffect(() => {
    socket.on(ACTIONS.ICE_CANDIDATE, ({ peerID, iceCandidate }) => {
      peerConnections.current[peerID]?.addIceCandidate(
        new RTCIceCandidate(iceCandidate)
      )
    })
    return () => socket.off(ACTIONS.ICE_CANDIDATE)
  }, [socket])

  useEffect(() => {
    const handleRemovePeer = ({ peerID }) => {
      if (peerConnections.current[peerID])
        peerConnections.current[peerID].close()
      delete peerConnections.current[peerID]
      delete peerMediaElements.current[peerID]
      updateClients((list) => list.filter((c) => c !== peerID))
    }

    socket.on(ACTIONS.REMOVE_PEER, handleRemovePeer)
    return () => socket.off(ACTIONS.REMOVE_PEER)
  }, [socket, updateClients])

  // === Capture flow ===
  useEffect(() => {
    async function startCapture() {
      try {
        const originalStream = await navigator.mediaDevices.getUserMedia({
          audio: {
            echoCancellation: true,
            noiseSuppression: true,
            autoGainControl: true,
            channelCount: 1,
          },
          video: {
            width: 1280,
            height: 720,
            frameRate: 30,
          },
        })

        const finalStream = await processAudioStream(originalStream)
        localMediaStream.current = finalStream

        addNewClient(LOCAL_VIDEO, () => {
          const localVideoElement = peerMediaElements.current[LOCAL_VIDEO]
          if (localVideoElement) {
            localVideoElement.volume = 0
            localVideoElement.srcObject = finalStream
          }
        })

        socket.emit(ACTIONS.JOIN, { room: roomID })
      } catch (error) {
        console.error('Error starting media capture:', error)
      }
    }

    startCapture()

    return () => {
      if (speakingCheckInterval.current) {
        clearInterval(speakingCheckInterval.current)
        speakingCheckInterval.current = null
      }
      if (silenceTimeout.current) {
        clearTimeout(silenceTimeout.current)
        silenceTimeout.current = null
      }
      if (localMediaStream.current) {
        localMediaStream.current.getTracks().forEach((track) => track.stop())
        localMediaStream.current = null
      }
      // leave room
      try {
        socket.emit(ACTIONS.LEAVE)
      } catch (e) {}
    }
  }, [roomID, socket, addNewClient, processAudioStream])

  const provideMediaRef = useCallback((id, node) => {
    peerMediaElements.current[id] = node
  }, [])

  return {
    clients,
    provideMediaRef,
    isSpeaking,
    thresholdDb,
    setThresholdDb,
  }
}
